steps:
  # Setup Poetry
  - name: 'python:3.11'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        python -m venv venv
        source venv/bin/activate
        pip install --upgrade pip
        pip install poetry==1.7.0

  # Install dependencies and build
  - name: 'python:3.11'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source venv/bin/activate
        poetry install
        poetry build

  # Submit Dataflow Job
  - name: 'python:3.11'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source venv/bin/activate
        python -m bigquery_to_datastore_via_beam.run \
        --name bigquery-to-datastore-via-beam-${_DATETIME} \
        --output gs://${PROJECT_ID}-temp/bigquery-to-datastore-via-beam/output \
        --temp_location gs://${PROJECT_ID}-temp/bigquery-to-datastore-via-beam/dataflow/temp \
        --project ${PROJECT_ID} \
        --region "${_REGION}" \
        --extra_packages ./dist/*.tar.gz \
        --network "${_NETWORK}" \
        --subnetwork "regions/${_REGION}/subnetworks/dataflow" \
        --service_account_email "${_SERVICE_ACCOUNT}" \
        --runner DataflowRunner \
        --save_main_session

substitutions:
  _REGION: europe-west2
  _DATETIME: <>
  _NETWORK: private
  _SERVICE_ACCOUNT: dataflow@${PROJECT_ID}.iam.gserviceaccount.com